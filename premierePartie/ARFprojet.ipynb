{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- linear mse ---\n",
      "('label pr\\xc3\\xa9dit: ', 2)\n",
      "('vrai label:   ', 2)\n",
      "('score: ', 0.9277528649725959)\n",
      "--- ridge regression ---\n",
      "('label pr\\xc3\\xa9dit: ', 2)\n",
      "('vrai label:   ', 2)\n",
      "('score: ', 0.92675635276532142)\n",
      "--- lasso regression ---\n",
      "('label pr\\xc3\\xa9dit: ', 2)\n",
      "('vrai label:   ', 2)\n",
      "('score: ', 0.90184354758345786)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def load_usps(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        f.readline()\n",
    "        data = [[float(x) for x in l.split()] for l in f if len(l.split()) >2]\n",
    "    tmp = np.array(data)\n",
    "    return tmp[:, 1:], tmp[:,0].astype(int)\n",
    "\n",
    "datax, datay =  load_usps(\"USPS/USPS_test.txt\")\n",
    "#print(datax[0].shape)\n",
    "\n",
    "def printchiffre(dataxchiffre):\n",
    "    #res= datax[0].reshape([16,16])\n",
    "    res=dataxchiffre.reshape([16,16])\n",
    "    #print(res.shape)\n",
    "    plt.imshow(res, cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "#printchiffre(datax[48])\n",
    "#print(datay[48])\n",
    "\n",
    "def printmatrix(matrixasvec): #envoyer classif.coef_[5] par ex\n",
    "    #affiche la matrice des poids pour un chiffre\n",
    "    res= matrixasvec.reshape([16,16])\n",
    "    plt.imshow(res, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "######################### LINEAR MSE ################################\n",
    "print(\"--- linear mse ---\")\n",
    "classif = OneVsRestClassifier(LinearRegression())\n",
    "classif.fit(datax, datay)\n",
    "\n",
    "def linear_getAllValueFor1Data(dataxchiffre):\n",
    "    res=[]\n",
    "    for i in range(0,10):\n",
    "        res2= classif.estimators_[i].predict(dataxchiffre)\n",
    "        res.append(res2)\n",
    "    return res\n",
    "def linear_predictValuefor1Data(dataxchiffre):\n",
    "    vec = linear_getAllValueFor1Data(dataxchiffre)\n",
    "    return np.argmax(vec)\n",
    "\n",
    "num=25\n",
    "#print(linear_getAllValueFor1Data(datax[num]))\n",
    "print(\"label prédit: \",linear_predictValuefor1Data(datax[num]))\n",
    "print(\"vrai label:   \", datay[num])\n",
    "#printchiffre(datax[num])\n",
    "\n",
    "score = classif.score(datax,datay)\n",
    "print(\"score: \",score)\n",
    "printmatrix(classif.coef_[8])\n",
    "\n",
    "######################### RIDGE ################################\n",
    "print(\"--- ridge regression ---\")\n",
    "classif = OneVsRestClassifier(Ridge(alpha=1))\n",
    "classif.fit(datax, datay)\n",
    "\n",
    "def ridge_getAllValueFor1Data(dataxchiffre):\n",
    "    res=[]\n",
    "    for i in range(0,10):\n",
    "        res2= classif.estimators_[i].predict(dataxchiffre)\n",
    "        res.append(res2)\n",
    "    return res\n",
    "def ridge_predictValuefor1Data(dataxchiffre):\n",
    "    vec = ridge_getAllValueFor1Data(dataxchiffre)\n",
    "    return np.argmax(vec)\n",
    "\n",
    "num=25\n",
    "#print(ridge_getAllValueFor1Data(datax[num]))\n",
    "print(\"label prédit: \",ridge_predictValuefor1Data(datax[num]))\n",
    "print(\"vrai label:   \", datay[num])\n",
    "#printchiffre(datax[num])\n",
    "\n",
    "score = classif.score(datax,datay)\n",
    "print(\"score: \",score)\n",
    "printmatrix(classif.coef_[8])\n",
    "\n",
    "######################### LASSO ################################\n",
    "print(\"--- lasso regression ---\")\n",
    "classif = OneVsRestClassifier(Lasso(alpha=0.001, fit_intercept=True))\n",
    "classif.fit(datax, datay)\n",
    "\n",
    "def lasso_getAllValueFor1Data(dataxchiffre):\n",
    "    res=[]\n",
    "    for i in range(0,10):\n",
    "        res2= classif.estimators_[i].predict(dataxchiffre)\n",
    "        res.append(res2)\n",
    "    return res\n",
    "def lasso_predictValuefor1Data(dataxchiffre):\n",
    "    vec = lasso_getAllValueFor1Data(dataxchiffre)\n",
    "    return np.argmax(vec)\n",
    "\n",
    "num=25\n",
    "#print(lasso_getAllValueFor1Data(datax[num]))\n",
    "print(\"label prédit: \",lasso_predictValuefor1Data(datax[num]))\n",
    "print(\"vrai label:   \", datay[num])\n",
    "#printchiffre(datax[num])\n",
    "weights = np.hstack((classif.intercept_, classif.coef_)) #adds bias to beginning\n",
    "#print(weights[1])\n",
    "   \n",
    "score = classif.score(datax,datay)\n",
    "print(\"score: \",score)\n",
    "printmatrix(classif.coef_[8])\n",
    "\n",
    "#############\n",
    "\n",
    "# voir \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
    "# ? pour prendre en compte la classification \"plug-in\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/25989720/regression-with-lasso-all-coeffs-are-0?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "\n",
    "To summarize the different priors (or penalties) commonly used to regularize least squares regression:\n",
    "\n",
    "    l2 penalty favors any number of non-zero coefficients but with very small absolute values (close to zero)\n",
    "    l1 penalty favors a small number of non-zero coefficients with small absolute values.\n",
    "    l0 favors a small number of non zero coefficients of any absolute value.\n",
    "\n",
    "l0 being non-convex, it is often not as easy to optimize as l1 and l2. This is why people use l1 (lasso) or l1 + l2 (elastic net) in practice to find sparse solutions even if not as clean as l0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
